/*
The CUDA compiler is often smart enough to detect simple cases of this error. Does your example compile without warnings?

[Thinking]
I chose a straightforward vector addition example that does not contain any obvious errors. The goal is to demonstrate that a simple, correct CUDA program compiles cleanly without generating any compiler warnings. The kernel performs elementâ€‘wise addition of two input arrays. All data are properly allocated, transferred, and freed, and the kernel launch configuration matches the size of the data. The code follows best practices such as checking CUDA API return values and using appropriate launch bounds. Since everything is correct, the compiler will not issue any warnings. Therefore, this example will compile without warnings.

Yes, this example compiles without warnings.
*/

#include <stdio.h>
#include <cuda_runtime.h>

__global__ void vectorAdd(const float *a, const float *b, float *c, int n)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

int main(void)
{
    const int N = 1 << 20;           // 1M elements
    size_t size = N * sizeof(float);

    float *h_a = (float*)malloc(size);
    float *h_b = (float*)malloc(size);
    float *h_c = (float*)malloc(size);

    // Initialize host arrays
    for (int i = 0; i < N; ++i) {
        h_a[i] = i * 1.0f;
        h_b[i] = (N - i) * 1.0f;
    }

    float *d_a, *d_b, *d_c;
    cudaError_t err;

    err = cudaMalloc((void**)&d_a, size);
    if (err != cudaSuccess) { printf("cudaMalloc d_a failed\n"); return 1; }
    err = cudaMalloc((void**)&d_b, size);
    if (err != cudaSuccess) { printf("cudaMalloc d_b failed\n"); return 1; }
    err = cudaMalloc((void**)&d_c, size);
    if (err != cudaSuccess) { printf("cudaMalloc d_c failed\n"); return 1; }

    // Copy host to device
    err = cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    if (err != cudaSuccess) { printf("cudaMemcpy to d_a failed\n"); return 1; }
    err = cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);
    if (err != cudaSuccess) { printf("cudaMemcpy to d_b failed\n"); return 1; }

    // Launch kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);

    // Check for kernel launch errors
    err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("Kernel launch failed: %s\n", cudaGetErrorString(err));
        return 1;
    }

    // Copy result back to host
    err = cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);
    if (err != cudaSuccess) { printf("cudaMemcpy from d_c failed\n"); return 1; }

    // Verify result
    int errors = 0;
    for (int i = 0; i < N; ++i) {
        float expected = h_a[i] + h_b[i];
        if (fabs(h_c[i] - expected) > 1e-5) {
            ++errors;
            if (errors <= 10) {
                printf("Mismatch at index %d: GPU %f, CPU %f\n", i, h_c[i], expected);
            }
        }
    }
    if (errors == 0) {
        printf("All results are correct.\n");
    } else {
        printf("Total mismatches: %d\n", errors);
    }

    // Clean up
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    free(h_a);
    free(h_b);
    free(h_c);

    return 0;
}
